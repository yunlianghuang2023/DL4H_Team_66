{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lEGHI_GEdRXi"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.insert(0, '../')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fH454-Ir-fev",
        "outputId": "e808f2f2-2685-475c-d5fb-f1ba4d3e91b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "common\n"
          ]
        }
      ],
      "source": [
        "!ls '/content/data/'\n",
        "!rm -r /content/data/*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgAabE9S-URA",
        "outputId": "5cce08e6-e1ce-46d4-d3f2-25e48eda24b3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Retrieving folder contents\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Retrieving folder 1-aVlnWRggV0rfhqBSUNnbKGARNfgL2T4 common\n",
            "Processing file 16o7RxcM2edO_jedQX1OI4Oy2cQF3vXOQ __init__.py\n",
            "Retrieving folder 1BxCK657k5wZNljexMoFuWYQvBI3tln_W __pycache__\n",
            "Processing file 1-EAgBnmO206Vs9xLUOJzBp2841vgvHTd __init__.cpython-310.pyc\n",
            "Processing file 1-E2xwNE1Z-ThHttjI5EaN2VR81a8xR1Z common.cpython-310.pyc\n",
            "Processing file 1-DRT2KBjsR4k1NzPV3gtePzKXJKD_yLm pytorch.cpython-310.pyc\n",
            "Processing file 1ZSfMTnVoRq-LpnVoqO8pNEnsEMc2tiL5 common.py\n",
            "Processing file 19M3f8ePOVAgSDM1xxeRrwaUoVJGitU7n pytorch.py\n",
            "Processing file 10vBmvv_4Ey4ZOp_cDH3y9aSsnXsTh8T3 data.parquet\n",
            "Processing file 1AtA2fLk6HslJ8lIrKru33SSqROyUCNUc data1.parquet\n",
            "Retrieving folder 1Jmq6qCOnqCxliC-RZOS9kNdk5CJJe4SU dataLoader\n",
            "Processing file 1klB8-1EcGtf5WlDaCvw9yuOFpN2YXVPS __init__.py\n",
            "Retrieving folder 1-KeVb3fzLZuCGbGexK-D-9u4btJX3HWX __pycache__\n",
            "Processing file 1-tN81SdzC_LE4L3eK5ZGZ-pQb4k1gqIy __init__.cpython-310.pyc\n",
            "Processing file 1-q3d0Oz1I2YUPVEJ_-N-U8_uNLK_PjDt MLM.cpython-310.pyc\n",
            "Processing file 1-jl9e1ugQThhiBHn-22SVhZ930ZC9pmE utils.cpython-310.pyc\n",
            "Processing file 1JvAeS5NiGqAuRU_FXLwowVN-j0OHBgtw MLM_v0.py\n",
            "Processing file 1jctb92-9iO4hs3RGGNOBBT2Mz7MoLPU2 MLM.py\n",
            "Processing file 1MxJTyDRoe8i3rqxIgQzD-uR0lbt5a4GQ NextXVisit.py\n",
            "Processing file 1gWzvmTDZ-fcX77q9j3gHxG_IwoYeLQDT utils.py\n",
            "Retrieving folder 1YNoy2kZXl8fdGaDHzfgIiROfRHkYlsWR figures\n",
            "Processing file 17WTIhgbKq9RenerUvjaLGvuamCAKGJQj model.png\n",
            "Processing file 1k3xg8LDKA-yZDz48zGCI5aDUfLWsZsnO results.png\n",
            "Processing file 104oZdoLCab0FC4CU0eN3QCcLmDE91jgz Make_data_parquet_file.ipynb\n",
            "Processing file 1N44LKrL1ugfZ723UG4X90Ls3V_e2NqCj MLM_UIUC1.ipynb\n",
            "Retrieving folder 1R5nVdwDfsHy6pDwpLoB4z_aX0m8plUQn model\n",
            "Processing file 1vhwMLTvpWp4RCDEK6MbzlVPhVWZWuL-9 __init__.py\n",
            "Retrieving folder 1-D-YVUKkr7BVziyhd49L8Q5c9hG2x5R7 __pycache__\n",
            "Processing file 1-R8mmNiFlMoPxoUTr4T0vo55j0TxToPG __init__.cpython-310.pyc\n",
            "Processing file 1-JGrw62AYaSgY8VSTNbHLdgU0mFLXR3Y MLM.cpython-310.pyc\n",
            "Processing file 1-Gb1p2Ky9pfUo1BRUfXjQd5ITc9f9256 optimiser.cpython-310.pyc\n",
            "Processing file 1-PltCqJlySRjrl6VxdGLa3mgLuKxLfNb utils.cpython-310.pyc\n",
            "Processing file 1ZpfkbA6Kntb8VJ1prMJEvNlsLuzS0Y1o MLM_GoodDebug_Liang.py\n",
            "Processing file 1eUmADJM7mIIuStqcLDKBqirDT79RpnKX MLM_v0.py\n",
            "Processing file 1Ge6DQb0SCBQEPmn9Ri0z-dVX414AAS_i MLM.py\n",
            "Processing file 1ZwqeSnIkthhvrjzn8Fdw88fxK0eD-owF NextXVisit.py\n",
            "Processing file 1iw8WLD3to8PF-_4OhEWtv4zXgfLjfwRq optimiser.py\n",
            "Processing file 1e0pYykxJls-71ANzscpUoSYCxgtc6pRX utils.py\n",
            "Processing file 16tPVlxe4_X8WrgDFTuzJ0p25JgVyuE45 NextXVisit_UIUC.ipynb\n",
            "Processing file 1TH7Vr6q08DRCLfUBad6us4sutoplzLHp optimiser.py\n",
            "Retrieving folder 1AusYaTSxmRoVvaE4WNz_6RLJJv8pDlCP Results\n",
            "Processing file 1v8lvQlevMgUJ8n4wjGfyzAlQkH5V607K MLM-Results.txt\n",
            "Processing file 1-ucPglFFW7Elpome0PaXXwyyxddD5uLV Test\n",
            "Retrieving folder 1-tt4NOtCbessRCDA6msBbYftWiTHIc4y Test_t\n",
            "Processing file 19C51KwVWnFlvE08nHpSYQfU1jObws3-r token2idx_make.ipynb\n",
            "Processing file 1czTT0orcpkizJNMLZ3xP7OeLzmKCVLQv vocab_token_idx.pkl\n",
            "Processing file 1XyYodjmlUi0xExZXHETjIFlCxypxZujK vocab_token_idx0.pkl\n",
            "Processing file 1qJ8GkF5YD3-ZKh9a9iq_d9JgWoqj6x-d vocab_token_idx1.pkl\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Retrieving folder contents completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=16o7RxcM2edO_jedQX1OI4Oy2cQF3vXOQ\n",
            "To: /content/data/common/__init__.py\n",
            "0.00B [00:00, ?B/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1-EAgBnmO206Vs9xLUOJzBp2841vgvHTd\n",
            "From (redirected): https://drive.google.com/uc?id=1-EAgBnmO206Vs9xLUOJzBp2841vgvHTd&confirm=t&uuid=03340159-9725-4a24-858b-885e84bc55da\n",
            "To: /content/data/common/__pycache__/__init__.cpython-310.pyc\n",
            "100%|██████████| 164/164 [00:00<00:00, 166kB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1-E2xwNE1Z-ThHttjI5EaN2VR81a8xR1Z\n",
            "From (redirected): https://drive.google.com/uc?id=1-E2xwNE1Z-ThHttjI5EaN2VR81a8xR1Z&confirm=t&uuid=49f748da-86cd-4c39-bad6-f00ce5544eb6\n",
            "To: /content/data/common/__pycache__/common.cpython-310.pyc\n",
            "100%|██████████| 1.71k/1.71k [00:00<00:00, 1.70MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1-DRT2KBjsR4k1NzPV3gtePzKXJKD_yLm\n",
            "From (redirected): https://drive.google.com/uc?id=1-DRT2KBjsR4k1NzPV3gtePzKXJKD_yLm&confirm=t&uuid=80ffc68c-ad58-4883-a396-8b98fb091219\n",
            "To: /content/data/common/__pycache__/pytorch.cpython-310.pyc\n",
            "100%|██████████| 906/906 [00:00<00:00, 2.73MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1ZSfMTnVoRq-LpnVoqO8pNEnsEMc2tiL5\n",
            "From (redirected): https://drive.google.com/uc?id=1ZSfMTnVoRq-LpnVoqO8pNEnsEMc2tiL5&confirm=t&uuid=5bb4bbeb-5b2d-40ad-b28c-e9adf070a097\n",
            "To: /content/data/common/common.py\n",
            "100%|██████████| 787/787 [00:00<00:00, 2.29MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=19M3f8ePOVAgSDM1xxeRrwaUoVJGitU7n\n",
            "From (redirected): https://drive.google.com/uc?id=19M3f8ePOVAgSDM1xxeRrwaUoVJGitU7n&confirm=t&uuid=7da06913-1c29-40f0-b5f2-42195dd38a5c\n",
            "To: /content/data/common/pytorch.py\n",
            "100%|██████████| 820/820 [00:00<00:00, 907kB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=10vBmvv_4Ey4ZOp_cDH3y9aSsnXsTh8T3\n",
            "To: /content/data/data.parquet\n",
            "100%|██████████| 1.53M/1.53M [00:00<00:00, 14.2MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1AtA2fLk6HslJ8lIrKru33SSqROyUCNUc\n",
            "To: /content/data/data1.parquet\n",
            "100%|██████████| 3.30M/3.30M [00:00<00:00, 26.1MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1klB8-1EcGtf5WlDaCvw9yuOFpN2YXVPS\n",
            "To: /content/data/dataLoader/__init__.py\n",
            "0.00B [00:00, ?B/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1-tN81SdzC_LE4L3eK5ZGZ-pQb4k1gqIy\n",
            "From (redirected): https://drive.google.com/uc?id=1-tN81SdzC_LE4L3eK5ZGZ-pQb4k1gqIy&confirm=t&uuid=0b3df3d0-d184-44c9-ab6d-8cd911784645\n",
            "To: /content/data/dataLoader/__pycache__/__init__.cpython-310.pyc\n",
            "100%|██████████| 168/168 [00:00<00:00, 447kB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1-q3d0Oz1I2YUPVEJ_-N-U8_uNLK_PjDt\n",
            "From (redirected): https://drive.google.com/uc?id=1-q3d0Oz1I2YUPVEJ_-N-U8_uNLK_PjDt&confirm=t&uuid=33dd36e5-7021-43cf-b9d1-9bdade7ee85f\n",
            "To: /content/data/dataLoader/__pycache__/MLM.cpython-310.pyc\n",
            "100%|██████████| 1.98k/1.98k [00:00<00:00, 3.28MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1-jl9e1ugQThhiBHn-22SVhZ930ZC9pmE\n",
            "From (redirected): https://drive.google.com/uc?id=1-jl9e1ugQThhiBHn-22SVhZ930ZC9pmE&confirm=t&uuid=09286e8e-cabd-4e65-9c3d-08df3c153d31\n",
            "To: /content/data/dataLoader/__pycache__/utils.cpython-310.pyc\n",
            "100%|██████████| 1.71k/1.71k [00:00<00:00, 4.64MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1JvAeS5NiGqAuRU_FXLwowVN-j0OHBgtw\n",
            "From (redirected): https://drive.google.com/uc?id=1JvAeS5NiGqAuRU_FXLwowVN-j0OHBgtw&confirm=t&uuid=9b0a250b-ba35-4ab6-b777-e1d79bc3c77c\n",
            "To: /content/data/dataLoader/MLM_v0.py\n",
            "100%|██████████| 1.83k/1.83k [00:00<00:00, 5.57MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1jctb92-9iO4hs3RGGNOBBT2Mz7MoLPU2\n",
            "From (redirected): https://drive.google.com/uc?id=1jctb92-9iO4hs3RGGNOBBT2Mz7MoLPU2&confirm=t&uuid=af2dc7ef-458d-48b8-be85-8cffb7e71f63\n",
            "To: /content/data/dataLoader/MLM.py\n",
            "100%|██████████| 2.93k/2.93k [00:00<00:00, 2.82MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1MxJTyDRoe8i3rqxIgQzD-uR0lbt5a4GQ\n",
            "From (redirected): https://drive.google.com/uc?id=1MxJTyDRoe8i3rqxIgQzD-uR0lbt5a4GQ&confirm=t&uuid=80c50263-4e44-4d71-a607-552c31e777f5\n",
            "To: /content/data/dataLoader/NextXVisit.py\n",
            "100%|██████████| 2.29k/2.29k [00:00<00:00, 3.69MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1gWzvmTDZ-fcX77q9j3gHxG_IwoYeLQDT\n",
            "From (redirected): https://drive.google.com/uc?id=1gWzvmTDZ-fcX77q9j3gHxG_IwoYeLQDT&confirm=t&uuid=167632c2-66b9-4a98-9e54-804bb382b696\n",
            "To: /content/data/dataLoader/utils.py\n",
            "100%|██████████| 2.63k/2.63k [00:00<00:00, 2.63MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=17WTIhgbKq9RenerUvjaLGvuamCAKGJQj\n",
            "To: /content/data/figures/model.png\n",
            "100%|██████████| 186k/186k [00:00<00:00, 4.74MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1k3xg8LDKA-yZDz48zGCI5aDUfLWsZsnO\n",
            "To: /content/data/figures/results.png\n",
            "100%|██████████| 74.8k/74.8k [00:00<00:00, 3.45MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=104oZdoLCab0FC4CU0eN3QCcLmDE91jgz\n",
            "To: /content/data/Make_data_parquet_file.ipynb\n",
            "100%|██████████| 11.8k/11.8k [00:00<00:00, 14.6MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1N44LKrL1ugfZ723UG4X90Ls3V_e2NqCj\n",
            "To: /content/data/MLM_UIUC1.ipynb\n",
            "100%|██████████| 18.8k/18.8k [00:00<00:00, 51.2MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1vhwMLTvpWp4RCDEK6MbzlVPhVWZWuL-9\n",
            "To: /content/data/model/__init__.py\n",
            "0.00B [00:00, ?B/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1-R8mmNiFlMoPxoUTr4T0vo55j0TxToPG\n",
            "From (redirected): https://drive.google.com/uc?id=1-R8mmNiFlMoPxoUTr4T0vo55j0TxToPG&confirm=t&uuid=3e4d5c57-c908-43ea-bdd8-b1a9848a6d20\n",
            "To: /content/data/model/__pycache__/__init__.cpython-310.pyc\n",
            "100%|██████████| 163/163 [00:00<00:00, 495kB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1-JGrw62AYaSgY8VSTNbHLdgU0mFLXR3Y\n",
            "From (redirected): https://drive.google.com/uc?id=1-JGrw62AYaSgY8VSTNbHLdgU0mFLXR3Y&confirm=t&uuid=f96d5eda-f60b-4d46-8072-b4b04b5a6983\n",
            "To: /content/data/model/__pycache__/MLM.cpython-310.pyc\n",
            "100%|██████████| 4.41k/4.41k [00:00<00:00, 4.88MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1-Gb1p2Ky9pfUo1BRUfXjQd5ITc9f9256\n",
            "From (redirected): https://drive.google.com/uc?id=1-Gb1p2Ky9pfUo1BRUfXjQd5ITc9f9256&confirm=t&uuid=6efce03d-17b0-4650-814d-efdea602e2b8\n",
            "To: /content/data/model/__pycache__/optimiser.cpython-310.pyc\n",
            "100%|██████████| 1.17k/1.17k [00:00<00:00, 3.16MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1-PltCqJlySRjrl6VxdGLa3mgLuKxLfNb\n",
            "From (redirected): https://drive.google.com/uc?id=1-PltCqJlySRjrl6VxdGLa3mgLuKxLfNb&confirm=t&uuid=cccd8639-30e5-4818-b077-f7821e829092\n",
            "To: /content/data/model/__pycache__/utils.cpython-310.pyc\n",
            "100%|██████████| 616/616 [00:00<00:00, 495kB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1ZpfkbA6Kntb8VJ1prMJEvNlsLuzS0Y1o\n",
            "From (redirected): https://drive.google.com/uc?id=1ZpfkbA6Kntb8VJ1prMJEvNlsLuzS0Y1o&confirm=t&uuid=9c7eb4d8-4503-4184-bcdd-08577da6fc24\n",
            "To: /content/data/model/MLM_GoodDebug_Liang.py\n",
            "100%|██████████| 7.17k/7.17k [00:00<00:00, 7.49MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1eUmADJM7mIIuStqcLDKBqirDT79RpnKX\n",
            "From (redirected): https://drive.google.com/uc?id=1eUmADJM7mIIuStqcLDKBqirDT79RpnKX&confirm=t&uuid=db6723c6-3417-46b6-8504-ac9c43ff7e77\n",
            "To: /content/data/model/MLM_v0.py\n",
            "100%|██████████| 6.19k/6.19k [00:00<00:00, 19.1MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1Ge6DQb0SCBQEPmn9Ri0z-dVX414AAS_i\n",
            "From (redirected): https://drive.google.com/uc?id=1Ge6DQb0SCBQEPmn9Ri0z-dVX414AAS_i&confirm=t&uuid=f6b3bebc-06b0-4787-ab80-1fc0d1e340ec\n",
            "To: /content/data/model/MLM.py\n",
            "100%|██████████| 6.70k/6.70k [00:00<00:00, 9.06MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1ZwqeSnIkthhvrjzn8Fdw88fxK0eD-owF\n",
            "From (redirected): https://drive.google.com/uc?id=1ZwqeSnIkthhvrjzn8Fdw88fxK0eD-owF&confirm=t&uuid=857a896c-dab0-4e25-bcf1-172206924b9d\n",
            "To: /content/data/model/NextXVisit.py\n",
            "100%|██████████| 6.21k/6.21k [00:00<00:00, 5.45MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1iw8WLD3to8PF-_4OhEWtv4zXgfLjfwRq\n",
            "From (redirected): https://drive.google.com/uc?id=1iw8WLD3to8PF-_4OhEWtv4zXgfLjfwRq&confirm=t&uuid=03afe86c-ca2b-42ef-bb5e-758a9b448b7e\n",
            "To: /content/data/model/optimiser.py\n",
            "100%|██████████| 762/762 [00:00<00:00, 1.11MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1e0pYykxJls-71ANzscpUoSYCxgtc6pRX\n",
            "From (redirected): https://drive.google.com/uc?id=1e0pYykxJls-71ANzscpUoSYCxgtc6pRX&confirm=t&uuid=38ecbe76-45ad-4683-a1d0-721817f4f07c\n",
            "To: /content/data/model/utils.py\n",
            "100%|██████████| 636/636 [00:00<00:00, 2.31MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=16tPVlxe4_X8WrgDFTuzJ0p25JgVyuE45\n",
            "To: /content/data/NextXVisit_UIUC.ipynb\n",
            "100%|██████████| 39.1k/39.1k [00:00<00:00, 39.3MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1TH7Vr6q08DRCLfUBad6us4sutoplzLHp\n",
            "From (redirected): https://drive.google.com/uc?id=1TH7Vr6q08DRCLfUBad6us4sutoplzLHp&confirm=t&uuid=10b696cb-8c6c-4239-a142-51ae48b46aff\n",
            "To: /content/data/optimiser.py\n",
            "100%|██████████| 759/759 [00:00<00:00, 2.58MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1v8lvQlevMgUJ8n4wjGfyzAlQkH5V607K\n",
            "To: /content/data/Results/MLM-Results.txt\n",
            "100%|██████████| 4.11k/4.11k [00:00<00:00, 3.97MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-ucPglFFW7Elpome0PaXXwyyxddD5uLV\n",
            "To: /content/data/Test\n",
            "0.00B [00:00, ?B/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=19C51KwVWnFlvE08nHpSYQfU1jObws3-r\n",
            "To: /content/data/token2idx_make.ipynb\n",
            "100%|██████████| 17.4k/17.4k [00:00<00:00, 23.2MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1czTT0orcpkizJNMLZ3xP7OeLzmKCVLQv\n",
            "To: /content/data/vocab_token_idx.pkl\n",
            "100%|██████████| 609k/609k [00:00<00:00, 8.13MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1XyYodjmlUi0xExZXHETjIFlCxypxZujK\n",
            "To: /content/data/vocab_token_idx0.pkl\n",
            "100%|██████████| 609k/609k [00:00<00:00, 8.29MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1qJ8GkF5YD3-ZKh9a9iq_d9JgWoqj6x-d\n",
            "To: /content/data/vocab_token_idx1.pkl\n",
            "100%|██████████| 609k/609k [00:00<00:00, 6.88MB/s]\n",
            "Download completed\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['/content/data/common/__init__.py',\n",
              " '/content/data/common/__pycache__/__init__.cpython-310.pyc',\n",
              " '/content/data/common/__pycache__/common.cpython-310.pyc',\n",
              " '/content/data/common/__pycache__/pytorch.cpython-310.pyc',\n",
              " '/content/data/common/common.py',\n",
              " '/content/data/common/pytorch.py',\n",
              " '/content/data/data.parquet',\n",
              " '/content/data/data1.parquet',\n",
              " '/content/data/dataLoader/__init__.py',\n",
              " '/content/data/dataLoader/__pycache__/__init__.cpython-310.pyc',\n",
              " '/content/data/dataLoader/__pycache__/MLM.cpython-310.pyc',\n",
              " '/content/data/dataLoader/__pycache__/utils.cpython-310.pyc',\n",
              " '/content/data/dataLoader/MLM_v0.py',\n",
              " '/content/data/dataLoader/MLM.py',\n",
              " '/content/data/dataLoader/NextXVisit.py',\n",
              " '/content/data/dataLoader/utils.py',\n",
              " '/content/data/figures/model.png',\n",
              " '/content/data/figures/results.png',\n",
              " '/content/data/Make_data_parquet_file.ipynb',\n",
              " '/content/data/MLM_UIUC1.ipynb',\n",
              " '/content/data/model/__init__.py',\n",
              " '/content/data/model/__pycache__/__init__.cpython-310.pyc',\n",
              " '/content/data/model/__pycache__/MLM.cpython-310.pyc',\n",
              " '/content/data/model/__pycache__/optimiser.cpython-310.pyc',\n",
              " '/content/data/model/__pycache__/utils.cpython-310.pyc',\n",
              " '/content/data/model/MLM_GoodDebug_Liang.py',\n",
              " '/content/data/model/MLM_v0.py',\n",
              " '/content/data/model/MLM.py',\n",
              " '/content/data/model/NextXVisit.py',\n",
              " '/content/data/model/optimiser.py',\n",
              " '/content/data/model/utils.py',\n",
              " '/content/data/NextXVisit_UIUC.ipynb',\n",
              " '/content/data/optimiser.py',\n",
              " '/content/data/Results/MLM-Results.txt',\n",
              " '/content/data/Test',\n",
              " '/content/data/token2idx_make.ipynb',\n",
              " '/content/data/vocab_token_idx.pkl',\n",
              " '/content/data/vocab_token_idx0.pkl',\n",
              " '/content/data/vocab_token_idx1.pkl']"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import gdown\n",
        "# data folder\n",
        "url = \"https://drive.google.com/drive/folders/1-9q8sUlBhj8L_Tc18mI5rLlWvxI6JW0-?usp=drive_link\"\n",
        "output_dir = '/content/'\n",
        "\n",
        "# Create the output directory if it doesn't exist\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "gdown.download_folder(url, output=output_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yiB1Gc4g-0gN",
        "outputId": "abcb8349-1a47-4367-d9a9-d624e228e965"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current working directory: /content/data\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Set the run directory path\n",
        "run_directory = \"/content/data/\"\n",
        "\n",
        "# Change the current working directory\n",
        "os.chdir(run_directory)\n",
        "\n",
        "# Verify the current working directory\n",
        "print(\"Current working directory:\", os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8g72EI--_JUH",
        "outputId": "e6b6fdb8-9be3-4248-9947-7c83fdd70b22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch-pretrained-bert in /usr/local/lib/python3.10/dist-packages (0.6.2)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-bert) (2.2.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-bert) (1.25.2)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-bert) (1.34.99)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-bert) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-bert) (4.66.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-bert) (2023.12.25)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=0.4.1->pytorch-pretrained-bert) (12.4.127)\n",
            "Requirement already satisfied: botocore<1.35.0,>=1.34.99 in /usr/local/lib/python3.10/dist-packages (from boto3->pytorch-pretrained-bert) (1.34.99)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3->pytorch-pretrained-bert) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from boto3->pytorch-pretrained-bert) (0.10.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch-pretrained-bert) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch-pretrained-bert) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch-pretrained-bert) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch-pretrained-bert) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.99->boto3->pytorch-pretrained-bert) (2.8.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=0.4.1->pytorch-pretrained-bert) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=0.4.1->pytorch-pretrained-bert) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.99->boto3->pytorch-pretrained-bert) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch-pretrained-bert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "F6n1AoPddRXm"
      },
      "outputs": [],
      "source": [
        "from common.common import create_folder\n",
        "from common.pytorch import load_model\n",
        "from model.utils import age_vocab\n",
        "from common.common import load_obj\n",
        "from dataLoader.MLM import MLMLoader\n",
        "from torch.utils.data import DataLoader\n",
        "import pandas as pd\n",
        "from model.MLM import BertForMaskedLM\n",
        "from model.optimiser import adam\n",
        "import sklearn.metrics as skm\n",
        "import numpy as np\n",
        "import torch\n",
        "import time\n",
        "import torch.nn as nn\n",
        "import os\n",
        "\n",
        "from transformers import BertModel, BertConfig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "JyxhpE1MdRXn"
      },
      "outputs": [],
      "source": [
        "class CustomBertConfig(BertConfig):\n",
        "    def __init__(self, config):\n",
        "        super(CustomBertConfig, self).__init__(\n",
        "            vocab_size=config.get('vocab_size'),\n",
        "            hidden_size=config['hidden_size'],\n",
        "            num_hidden_layers=config.get('num_hidden_layers'),\n",
        "            num_attention_heads=config.get('num_attention_heads'),\n",
        "            intermediate_size=config.get('intermediate_size'),\n",
        "            hidden_act=config.get('hidden_act'),\n",
        "            hidden_dropout_prob=config.get('hidden_dropout_prob'),\n",
        "            attention_probs_dropout_prob=config.get('attention_probs_dropout_prob'),\n",
        "            max_position_embeddings = config.get('max_position_embedding'),\n",
        "            initializer_range=config.get('initializer_range'),\n",
        "        )\n",
        "        self.seg_vocab_size = config.get('seg_vocab_size')\n",
        "        self.age_vocab_size = config.get('age_vocab_size')\n",
        "\n",
        "class TrainConfig(object):\n",
        "    def __init__(self, config):\n",
        "        self.batch_size = config.get('batch_size')\n",
        "        self.use_cuda = config.get('use_cuda')\n",
        "        self.max_len_seq = config.get('max_len_seq')\n",
        "        self.train_loader_workers = config.get('train_loader_workers')\n",
        "        self.test_loader_workers = config.get('test_loader_workers')\n",
        "        self.device = config.get('device')\n",
        "        self.output_dir = config.get('output_dir')\n",
        "        self.output_name = config.get('output_name')\n",
        "        self.best_name = config.get('best_name')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5VUVoB2dRXn",
        "outputId": "a1ecc340-2d23-4978-ae39-98c6831bb749"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/data/Test_t\n"
          ]
        }
      ],
      "source": [
        "file_config = {\n",
        "    'vocab':'vocab_token_idx',  # vocabulary idx2token, token2idx\n",
        "    'data': 'data.parquet',  # formated data\n",
        "    'model_path': os.getcwd(), # where to save model\n",
        "    'model_name': 'myMLM', # model name\n",
        "    'file_name': 'Test',  # log path\n",
        "}\n",
        "full_path = os.path.join(file_config['model_path'], 'Test_t')\n",
        "print(full_path)\n",
        "#create_folder(file_config['model_path'])\n",
        "create_folder(full_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "kA8zMNxTdRXo"
      },
      "outputs": [],
      "source": [
        "global_params = {\n",
        "    'max_seq_len': 64,\n",
        "    'max_age': 110,\n",
        "    'month': 12,\n",
        "    'age_symbol': None,\n",
        "    'min_visit': 1,\n",
        "    'gradient_accumulation_steps': 1\n",
        "}\n",
        "\n",
        "optim_param = {\n",
        "    'lr': 3e-5,\n",
        "    'warmup_proportion': 0.1,\n",
        "    'weight_decay': 0.01\n",
        "}\n",
        "\n",
        "train_params = {\n",
        "    'batch_size': 256,\n",
        "    'use_cuda': True,\n",
        "    'max_len_seq': global_params['max_seq_len'],\n",
        "    'device': \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    #'device': \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "_57K5ntKdRXo"
      },
      "outputs": [],
      "source": [
        "BertVocab = load_obj(file_config['vocab'])\n",
        "ageVocab, _ = age_vocab(max_age=global_params['max_age'], mon=global_params['month'], symbol=global_params['age_symbol'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "PakzgrD8dRXp"
      },
      "outputs": [],
      "source": [
        "data = pd.read_parquet(file_config['data'])\n",
        "# remove patients with visits less than min visit\n",
        "data['length'] = data['caliber_id'].apply(lambda x: len([i for i in range(len(x)) if x[i] == 'SEP']))\n",
        "data = data[data['length'] >= global_params['min_visit']]\n",
        "data = data.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "sDutET7CdRXr",
        "outputId": "c265debc-88ca-482c-f94d-b26e7c6782ce"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 7537,\n  \"fields\": [\n    {\n      \"column\": \"caliber_id\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 41,\n        \"num_unique_values\": 25,\n        \"samples\": [\n          10,\n          21,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "data"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-9ec778ed-a05d-47e6-a5f3-ee97bf78b2fb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>caliber_id</th>\n",
              "      <th>age</th>\n",
              "      <th>length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[7455, 45829, V1259, 2724, SEP, 4239, 5119, 78...</td>\n",
              "      <td>[47, 47]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[41071, 78551, 5781, 5849, 40391, 4280, 4592, ...</td>\n",
              "      <td>[87, 87]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[41401, 4111, 4241, V4582, 2724, 4019, 60000, ...</td>\n",
              "      <td>[71, 75]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[41071, 4280, 4254, 42731, 9971, 4260, 41401, ...</td>\n",
              "      <td>[300, 304]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[41401, 4111, 496, 4019, 3051, 53081, 60000, V...</td>\n",
              "      <td>[69, 69, 72]</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7532</th>\n",
              "      <td>[V5811, 1960, 2536, 1481, V1582, 4019, V1046, ...</td>\n",
              "      <td>[61, 61, 61]</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7533</th>\n",
              "      <td>[41401, 42823, 5185, 49322, 9994, 4280, 99527,...</td>\n",
              "      <td>[73, 74]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7534</th>\n",
              "      <td>[25020, 5849, 42832, 4280, 2762, 5855, 40391, ...</td>\n",
              "      <td>[53, 54]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7535</th>\n",
              "      <td>[45829, 4532, 2761, 5723, 4561, 45621, 5849, 7...</td>\n",
              "      <td>[54, 54]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7536</th>\n",
              "      <td>[42823, 4254, 2875, 42731, 3970, 5303, 4280, V...</td>\n",
              "      <td>[65, 65, 65]</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7537 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9ec778ed-a05d-47e6-a5f3-ee97bf78b2fb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9ec778ed-a05d-47e6-a5f3-ee97bf78b2fb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9ec778ed-a05d-47e6-a5f3-ee97bf78b2fb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4bea1290-a527-4a24-9c05-a18147244b0a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4bea1290-a527-4a24-9c05-a18147244b0a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4bea1290-a527-4a24-9c05-a18147244b0a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_59944fb2-a2b0-4312-827e-ad33e849dcba\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_59944fb2-a2b0-4312-827e-ad33e849dcba button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                             caliber_id           age  length\n",
              "0     [7455, 45829, V1259, 2724, SEP, 4239, 5119, 78...      [47, 47]       1\n",
              "1     [41071, 78551, 5781, 5849, 40391, 4280, 4592, ...      [87, 87]       1\n",
              "2     [41401, 4111, 4241, V4582, 2724, 4019, 60000, ...      [71, 75]       1\n",
              "3     [41071, 4280, 4254, 42731, 9971, 4260, 41401, ...    [300, 304]       1\n",
              "4     [41401, 4111, 496, 4019, 3051, 53081, 60000, V...  [69, 69, 72]       2\n",
              "...                                                 ...           ...     ...\n",
              "7532  [V5811, 1960, 2536, 1481, V1582, 4019, V1046, ...  [61, 61, 61]       2\n",
              "7533  [41401, 42823, 5185, 49322, 9994, 4280, 99527,...      [73, 74]       1\n",
              "7534  [25020, 5849, 42832, 4280, 2762, 5855, 40391, ...      [53, 54]       1\n",
              "7535  [45829, 4532, 2761, 5723, 4561, 45621, 5849, 7...      [54, 54]       1\n",
              "7536  [42823, 4254, 2875, 42731, 3970, 5303, 4280, V...  [65, 65, 65]       2\n",
              "\n",
              "[7537 rows x 3 columns]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "IL4p7xnmdRXs"
      },
      "outputs": [],
      "source": [
        "Dset = MLMLoader(data, BertVocab['token2idx'], ageVocab, max_len=train_params['max_len_seq'], code='caliber_id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtvCNWBJdRXu",
        "outputId": "9d79a60b-6270-40c3-803f-1acf569b4372"
      },
      "outputs": [],
      "source": [
        "Dset = MLMLoader(data, BertVocab['token2idx'], ageVocab, max_len=train_params['max_len_seq'], code='caliber_id')\n",
        "#print(BertVocab['token2idx'])\n",
        "trainload = DataLoader(dataset=Dset, batch_size=train_params['batch_size'], shuffle=True, num_workers=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Y7Ql_Rb3dRXu"
      },
      "outputs": [],
      "source": [
        "model_config = {\n",
        "    'vocab_size': 100000, #len(BertVocab['token2idx'].keys())*8, # number of disease + symbols for word embedding\n",
        "    'hidden_size': 288, # word embedding and seg embedding hidden size\n",
        "    'seg_vocab_size': 2, # number of vocab for seg embedding\n",
        "    'age_vocab_size': len(ageVocab.keys()), # number of vocab for age embedding\n",
        "    'max_position_embedding': train_params['max_len_seq'], # maximum number of tokens\n",
        "    'hidden_dropout_prob': 0.1, # dropout rate\n",
        "    'num_hidden_layers': 6, # number of multi-head attention layers required\n",
        "    'num_attention_heads': 12, # number of attention heads\n",
        "    'attention_probs_dropout_prob': 0.1, # multi-head attention dropout rate\n",
        "    'intermediate_size': 512, # the size of the \"intermediate\" layer in the transformer encoder\n",
        "    'hidden_act': 'gelu', # The non-linear activation function in the encoder and the pooler \"gelu\", 'relu', 'swish' are supported\n",
        "    'initializer_range': 0.02, # parameter weight initializer range\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DceB593YtM9A",
        "outputId": "b0a8ec3b-e672-470a-becd-918e4de0ec98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100000\n"
          ]
        }
      ],
      "source": [
        "print(model_config['vocab_size'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "MvRdkgPxdRXu"
      },
      "outputs": [],
      "source": [
        "conf = CustomBertConfig(model_config)\n",
        "model = BertForMaskedLM(conf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlMCpSktdRXv",
        "outputId": "5249287b-6aef-4efa-f7d4-0dc024632b49"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:pytorch_pretrained_bert.optimization:t_total value of -1 results in schedule not being applied\n"
          ]
        }
      ],
      "source": [
        "model = model.to(train_params['device'])\n",
        "optim = adam(params=list(model.named_parameters()), config=optim_param)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "NE2QNPtQdRXv"
      },
      "outputs": [],
      "source": [
        "def cal_acc(label, pred):\n",
        "    logs = nn.LogSoftmax()\n",
        "    label=label.cpu().numpy()\n",
        "    ind = np.where(label!=-1)[0]\n",
        "    truepred = pred.detach().cpu().numpy()\n",
        "    truepred = truepred[ind]\n",
        "    truelabel = label[ind]\n",
        "    truepred = logs(torch.tensor(truepred))\n",
        "    outs = [np.argmax(pred_x) for pred_x in truepred.numpy()]\n",
        "    precision = skm.precision_score(truelabel, outs, average='micro')\n",
        "    return precision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "rn44Hp37dRXv"
      },
      "outputs": [],
      "source": [
        "def train(e, loader):\n",
        "    tr_loss = 0\n",
        "    temp_loss = 0\n",
        "    nb_tr_examples, nb_tr_steps = 0, 0\n",
        "    cnt= 0\n",
        "    start = time.time()\n",
        "\n",
        "    for step, batch in enumerate(loader):\n",
        "        cnt +=1\n",
        "        batch = tuple(t.to(train_params['device']) for t in batch)\n",
        "        age_ids, input_ids, posi_ids, segment_ids, attMask, masked_label = batch\n",
        "\n",
        "        loss, pred, label = model(input_ids, age_ids, segment_ids, posi_ids,attention_mask=attMask, masked_lm_labels=masked_label)\n",
        "\n",
        "        if global_params['gradient_accumulation_steps'] >1:\n",
        "            loss = loss/global_params['gradient_accumulation_steps']\n",
        "        loss.backward()\n",
        "\n",
        "        temp_loss += loss.item()\n",
        "        tr_loss += loss.item()\n",
        "\n",
        "        nb_tr_examples += input_ids.size(0)\n",
        "        nb_tr_steps += 1\n",
        "\n",
        "        if step % 200==0:\n",
        "            print(\"epoch: {}\\t| cnt: {}\\t|Loss: {}\\t| precision: {:.4f}\\t| time: {:.2f}\".format(e, cnt, temp_loss/2000, cal_acc(label, pred), time.time()-start))\n",
        "            temp_loss = 0\n",
        "            start = time.time()\n",
        "\n",
        "        if (step + 1) % global_params['gradient_accumulation_steps'] == 0:\n",
        "            optim.step()\n",
        "            optim.zero_grad()\n",
        "\n",
        "    print(\"** ** * Saving fine - tuned model ** ** * \")\n",
        "    model_to_save = model.module if hasattr(model, 'module') else model  # Only save the model it-self\n",
        "    create_folder(file_config['model_path'])\n",
        "    output_model_file = os.path.join(file_config['model_path'], file_config['model_name'])\n",
        "\n",
        "    torch.save(model_to_save.state_dict(), output_model_file)\n",
        "\n",
        "    cost = time.time() - start\n",
        "    return tr_loss, cost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "8nPjWsiT11zJ"
      },
      "outputs": [],
      "source": [
        "data_len = len(Dset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShnS4cSKdRXv",
        "outputId": "d3a4a9fd-6c3a-48c4-9ab6-3eb1cb5852d4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 0\t| cnt: 1\t|Loss: 0.0058879051208496095\t| precision: 0.0000\t| time: 6.99\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_pretrained_bert/optimization.py:275: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1630.)\n",
            "  next_m.mul_(beta1).add_(1 - beta1, grad)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "** ** * Saving fine - tuned model ** ** * \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 1\t| cnt: 1\t|Loss: 0.002469825029373169\t| precision: 1.0000\t| time: 5.95\n",
            "** ** * Saving fine - tuned model ** ** * \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 2\t| cnt: 1\t|Loss: 0.0018097984790802003\t| precision: 1.0000\t| time: 6.19\n",
            "** ** * Saving fine - tuned model ** ** * \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 3\t| cnt: 1\t|Loss: 0.0012871360778808595\t| precision: 1.0000\t| time: 5.88\n",
            "** ** * Saving fine - tuned model ** ** * \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 4\t| cnt: 1\t|Loss: 0.0008566773533821106\t| precision: 1.0000\t| time: 5.94\n",
            "** ** * Saving fine - tuned model ** ** * \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 5\t| cnt: 1\t|Loss: 0.0005225066542625427\t| precision: 1.0000\t| time: 5.96\n",
            "** ** * Saving fine - tuned model ** ** * \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 6\t| cnt: 1\t|Loss: 0.0002923850119113922\t| precision: 1.0000\t| time: 5.95\n",
            "** ** * Saving fine - tuned model ** ** * \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 7\t| cnt: 1\t|Loss: 0.00015406085550785065\t| precision: 1.0000\t| time: 5.98\n",
            "** ** * Saving fine - tuned model ** ** * \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 8\t| cnt: 1\t|Loss: 7.911865413188934e-05\t| precision: 1.0000\t| time: 5.93\n",
            "** ** * Saving fine - tuned model ** ** * \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 9\t| cnt: 1\t|Loss: 4.062308743596077e-05\t| precision: 1.0000\t| time: 5.87\n",
            "** ** * Saving fine - tuned model ** ** * \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 10\t| cnt: 1\t|Loss: 2.1412862464785575e-05\t| precision: 1.0000\t| time: 5.92\n",
            "** ** * Saving fine - tuned model ** ** * \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 11\t| cnt: 1\t|Loss: 1.3599499128758908e-05\t| precision: 1.0000\t| time: 5.92\n",
            "** ** * Saving fine - tuned model ** ** * \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 12\t| cnt: 1\t|Loss: 1.0029583238065244e-05\t| precision: 1.0000\t| time: 5.91\n",
            "** ** * Saving fine - tuned model ** ** * \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 13\t| cnt: 1\t|Loss: 7.969777099788189e-06\t| precision: 1.0000\t| time: 5.88\n",
            "** ** * Saving fine - tuned model ** ** * \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 14\t| cnt: 1\t|Loss: 6.615400314331055e-06\t| precision: 1.0000\t| time: 5.92\n",
            "** ** * Saving fine - tuned model ** ** * \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 15\t| cnt: 1\t|Loss: 5.6537757627665995e-06\t| precision: 1.0000\t| time: 6.01\n",
            "** ** * Saving fine - tuned model ** ** * \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 16\t| cnt: 1\t|Loss: 4.930169321596623e-06\t| precision: 1.0000\t| time: 5.95\n",
            "** ** * Saving fine - tuned model ** ** * \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 17\t| cnt: 1\t|Loss: 4.367179237306118e-06\t| precision: 1.0000\t| time: 5.94\n",
            "** ** * Saving fine - tuned model ** ** * \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 18\t| cnt: 1\t|Loss: 3.915234934538603e-06\t| precision: 1.0000\t| time: 5.87\n",
            "** ** * Saving fine - tuned model ** ** * \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 19\t| cnt: 1\t|Loss: 3.5436246544122697e-06\t| precision: 1.0000\t| time: 5.93\n",
            "** ** * Saving fine - tuned model ** ** * \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 20\t| cnt: 1\t|Loss: 3.231626469641924e-06\t| precision: 1.0000\t| time: 5.95\n",
            "** ** * Saving fine - tuned model ** ** * \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 21\t| cnt: 1\t|Loss: 2.9656949918717146e-06\t| precision: 1.0000\t| time: 5.96\n",
            "** ** * Saving fine - tuned model ** ** * \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 22\t| cnt: 1\t|Loss: 2.737668575718999e-06\t| precision: 1.0000\t| time: 5.92\n",
            "** ** * Saving fine - tuned model ** ** * \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 23\t| cnt: 1\t|Loss: 2.541261026635766e-06\t| precision: 1.0000\t| time: 5.95\n",
            "** ** * Saving fine - tuned model ** ** * \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 24\t| cnt: 1\t|Loss: 2.368210582062602e-06\t| precision: 1.0000\t| time: 5.92\n",
            "** ** * Saving fine - tuned model ** ** * \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 25\t| cnt: 1\t|Loss: 2.216292079538107e-06\t| precision: 1.0000\t| time: 5.89\n",
            "** ** * Saving fine - tuned model ** ** * \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 26\t| cnt: 1\t|Loss: 2.0820240024477244e-06\t| precision: 1.0000\t| time: 5.93\n",
            "** ** * Saving fine - tuned model ** ** * \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 27\t| cnt: 1\t|Loss: 1.9603148102760313e-06\t| precision: 1.0000\t| time: 5.96\n",
            "** ** * Saving fine - tuned model ** ** * \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 28\t| cnt: 1\t|Loss: 1.8515883712098002e-06\t| precision: 1.0000\t| time: 5.92\n",
            "** ** * Saving fine - tuned model ** ** * \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 29\t| cnt: 1\t|Loss: 1.7530982149764895e-06\t| precision: 1.0000\t| time: 5.89\n",
            "** ** * Saving fine - tuned model ** ** * \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 30\t| cnt: 1\t|Loss: 1.6625316347926856e-06\t| precision: 1.0000\t| time: 5.96\n",
            "** ** * Saving fine - tuned model ** ** * \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 31\t| cnt: 1\t|Loss: 1.5805878210812808e-06\t| precision: 1.0000\t| time: 5.90\n",
            "** ** * Saving fine - tuned model ** ** * \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 32\t| cnt: 1\t|Loss: 1.5050910878926516e-06\t| precision: 1.0000\t| time: 5.92\n",
            "** ** * Saving fine - tuned model ** ** * \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 33\t| cnt: 1\t|Loss: 1.4360679779201745e-06\t| precision: 1.0000\t| time: 5.89\n",
            "** ** * Saving fine - tuned model ** ** * \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 34\t| cnt: 1\t|Loss: 1.3718025293201208e-06\t| precision: 1.0000\t| time: 5.92\n",
            "** ** * Saving fine - tuned model ** ** * \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 35\t| cnt: 1\t|Loss: 1.312459586188197e-06\t| precision: 1.0000\t| time: 5.91\n",
            "** ** * Saving fine - tuned model ** ** * \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 36\t| cnt: 1\t|Loss: 1.2574505526572466e-06\t| precision: 1.0000\t| time: 5.92\n",
            "** ** * Saving fine - tuned model ** ** * \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 37\t| cnt: 1\t|Loss: 1.2059566797688603e-06\t| precision: 1.0000\t| time: 5.95\n",
            "** ** * Saving fine - tuned model ** ** * \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 38\t| cnt: 1\t|Loss: 1.1580736609175801e-06\t| precision: 1.0000\t| time: 5.91\n",
            "** ** * Saving fine - tuned model ** ** * \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 39\t| cnt: 1\t|Loss: 1.1132280342280865e-06\t| precision: 1.0000\t| time: 5.93\n",
            "** ** * Saving fine - tuned model ** ** * \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 40\t| cnt: 1\t|Loss: 1.0707129258662461e-06\t| precision: 1.0000\t| time: 5.94\n",
            "** ** * Saving fine - tuned model ** ** * \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 41\t| cnt: 1\t|Loss: 1.0313414968550206e-06\t| precision: 1.0000\t| time: 5.95\n",
            "** ** * Saving fine - tuned model ** ** * \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 42\t| cnt: 1\t|Loss: 9.942027973011137e-07\t| precision: 1.0000\t| time: 5.93\n",
            "** ** * Saving fine - tuned model ** ** * \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 43\t| cnt: 1\t|Loss: 9.591806447133423e-07\t| precision: 1.0000\t| time: 5.93\n",
            "** ** * Saving fine - tuned model ** ** * \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 44\t| cnt: 1\t|Loss: 9.257839992642403e-07\t| precision: 1.0000\t| time: 5.90\n",
            "** ** * Saving fine - tuned model ** ** * \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 45\t| cnt: 1\t|Loss: 8.945832378230989e-07\t| precision: 1.0000\t| time: 5.88\n",
            "** ** * Saving fine - tuned model ** ** * \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 46\t| cnt: 1\t|Loss: 8.649108349345625e-07\t| precision: 1.0000\t| time: 5.89\n",
            "** ** * Saving fine - tuned model ** ** * \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 47\t| cnt: 1\t|Loss: 8.369119605049491e-07\t| precision: 1.0000\t| time: 5.89\n",
            "** ** * Saving fine - tuned model ** ** * \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 48\t| cnt: 1\t|Loss: 8.101253770291805e-07\t| precision: 1.0000\t| time: 5.94\n",
            "** ** * Saving fine - tuned model ** ** * \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 49\t| cnt: 1\t|Loss: 7.847143569961191e-07\t| precision: 1.0000\t| time: 5.88\n",
            "** ** * Saving fine - tuned model ** ** * \n"
          ]
        }
      ],
      "source": [
        "f = open(os.path.join(file_config['model_path'], file_config['file_name']), \"w\")\n",
        "f.write('{}\\t{}\\t{}\\n'.format('epoch', 'loss', 'time'))\n",
        "for e in range(50):\n",
        "    loss, time_cost = train(e, trainload)\n",
        "    loss = loss/data_len\n",
        "    f.write('{}\\t{}\\t{}\\n'.format(e, loss, time_cost))\n",
        "f.close()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
